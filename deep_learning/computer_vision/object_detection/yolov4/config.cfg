[net]
# Testing
batch=64
subdivisions=16
# Training
# batch=64
# subdivisions=16
width=416
height=416
channels=3
momentum=0.949
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001 # Ini adalah nilai learning rate atau laju pembelajaran yang digunakan pada model. Semakin besar nilai ini, semakin besar perubahan pada setiap iterasi pelatihan. Nilai yang terlalu besar dapat menyebabkan model kehilangan konvergensi atau kestabilan, sedangkan nilai yang terlalu kecil dapat membuat pelatihan lebih lambat.
burn_in=1000 # Burn-in period adalah periode awal pelatihan di mana learning rate diturunkan secara bertahap dari nilai awal yang lebih besar ke nilai yang lebih kecil. Pada konfigurasi ini, burn-in period berlangsung selama 1000 batch perta
max_batches = 50000 # Ini adalah jumlah maksimum batch yang akan dipelajari oleh model. Semakin banyak batch yang dipelajari, semakin lama pelatihan akan berlangsung. Namun, jumlah batch yang terlalu sedikit dapat menyebabkan model tidak cukup terlatih.
policy=steps # Ini menunjukkan bahwa penjadwalan learning rate yang digunakan adalah dengan metode step.
steps=40000,45000 # Pada metode step, learning rate diturunkan setiap kali jumlah batch pelatihan mencapai angka yang ditentukan. Dalam konfigurasi ini, learning rate akan diturunkan pada batch ke-40000 dan batch ke-45000
scales=.1,.1 # Ini adalah faktor dengan nilai antara 0 dan 1 yang mengontrol seberapa banyak learning rate akan diturunkan. Dalam konfigurasi ini, learning rate akan diturunkan sebesar 10% pada setiap step

[yolo]
mask = 0,1,2
anchors = 12,16, 19,36, 40,28, 36,75, 76,55, 72,146, 142,110, 192,243, 459,401
classes=3
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5
pad=1.5
box_loss = .05
# scale = 1.05
cls_alpha = 0.5

[convolutional]
size=1
stride=1
pad=1
filters=18
activation=linear

[yolo]
mask = 3,4,5
anchors = 12,36, 37,58, 81,82, 135,169, 344,319, 192,423, 459,401, 655,689, 770,847
classes=3
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5
pad=1.5
box_loss = .05
# scale = 1.05
cls_alpha = 0.5

[convolutional]
size=1
stride=1
pad=1
filters=18
activation=linear

[yolo]
mask = 6,7,8
anchors = 12,16, 19,36, 40,28, 36,75, 76,55, 72,146, 142,110, 192,243, 459,401
classes=3
num=9

# Variabel BATCH_SIZE dan STEPS_PER_EPOCH: Menentukan ukuran batch dan jumlah iterasi yang akan dilakukan pada setiap epoch selama pelatihan. Dalam contoh ini, BATCH_SIZE diatur sebagai 8 dan STEPS_PER_EPOCH diatur sebagai 100.

# Variabel CLASSES dan NUM_CLASSES: Menentukan jumlah dan daftar kelas yang akan diidentifikasi oleh model. Dalam contoh ini, dataset YouTube-Objects memiliki 10 kelas, sehingga NUM_CLASSES diatur sebagai 10 dan CLASSES berisi daftar 10 kelas tersebut.

# Variabel ANCHORS: Menentukan ukuran anchor boxes yang akan digunakan oleh model selama pelatihan. Dalam contoh ini, ANCHORS diatur dengan memuat daftar nilai lebar dan tinggi anchor box dalam pixel.

# Variabel TRAIN_TFRECORDS dan VALID_TFRECORDS: Menentukan lokasi dari file TFRecord yang berisi data pelatihan dan validasi. Dalam contoh ini, file-file tersebut disimpan di direktori ./data/tfrecords/.

# Variabel SAVE_PERIOD: Menentukan frekuensi penyimpanan model selama pelatihan. Dalam contoh ini, model akan disimpan setiap 5 epoch.

# Variabel model: Mendefinisikan arsitektur model YOLOv4 menggunakan fungsi yolo dari modul yolov4.model. Model tersebut kemudian dikompilasi dengan optimizer Adam dan metrik mAP.

# Variabel callbacks: Menentukan daftar fungsi callback yang akan dijalankan selama pelatihan. Dalam contoh ini, digunakan 3 fungsi callback, yaitu EarlyStopping, ReduceLROnPlateau, dan ModelCheckpoint. Fungsi EarlyStopping akan menghentikan pelatihan apabila nilai validasi tidak meningkat selama 10 epoch berturut-turut. Fungsi ReduceLROnPlateau akan mengurangi learning rate model jika nilai validasi tidak meningkat selama 2 epoch berturut-turut. Fungsi ModelCheckpoint akan menyimpan model setiap 5 epoch pada direktori ./data/checkpoints/.